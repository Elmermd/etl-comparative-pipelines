{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64799e14-3df1-4a5f-ba48-d49543e2e8ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/Volumes/workspace/default/raw_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6e9ba21-13f5-49ad-8c11-e2687d2da22f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **ETL datos de clientes y sus suscripciones a una plataforma digital.**\n",
    "El objetivo es generar métricas limpias y confiables para análisis financiero, construyendo un dataset agregado con:\n",
    "- país\n",
    "- tipo_suscripcion\n",
    "- ingreso_promedio_anual\n",
    "- total_clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c8eaa4-a60d-4bb3-af71-9aa0affe992d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count\n",
    "\n",
    "\n",
    "# Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"digital_platform\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "# Carga de datos\n",
    "df_clientes = (\n",
    "    spark.read.csv(\n",
    "        \"/Volumes/workspace/default/raw_data/clientes_proyecto.csv\",\n",
    "        header=True,\n",
    "        inferSchema=True\n",
    "    )\n",
    ")\n",
    "\n",
    "df_suscripciones = (\n",
    "    spark.read.csv(\n",
    "        \"/Volumes/workspace/default/raw_data/suscripciones_proyecto.csv\",\n",
    "        header=True,\n",
    "        inferSchema=True\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Unión de datasets\n",
    "df = (\n",
    "    df_clientes\n",
    "    .join(\n",
    "        df_suscripciones,\n",
    "        on=\"cliente_id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    ")\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "\n",
    "# Verificación inicial de valores nulos\n",
    "for columna in df.columns:\n",
    "    print(\n",
    "        f\"Nulos en {columna}: \",\n",
    "        df.filter(col(columna).isNull()).count()\n",
    "    )\n",
    "\n",
    "\n",
    "# Limpieza e imputación de datos\n",
    "print('\\nValores nulos en columnas tipo_suscripcion y estado_suscripcion deben ser eliminados.')\n",
    "print('Imputamos columnas de edad y pago_mensual con el valor medio.')\n",
    "print('Imputamos columna pais con la palabra: \"Desconocido\".')\n",
    "\n",
    "df = df.dropna(\n",
    "    subset=[\"tipo_suscripcion\", \"estado_suscripcion\"]\n",
    ")\n",
    "\n",
    "promedio = (\n",
    "    df\n",
    "    .select(\n",
    "        avg(col(\"edad\")).alias(\"promedio_edad\"),\n",
    "        avg(col(\"pago_mensual\")).alias(\"promedio_pago\")\n",
    "    )\n",
    "    .first()\n",
    ")\n",
    "\n",
    "df = df.fillna({\n",
    "    \"edad\": promedio[\"promedio_edad\"],\n",
    "    \"pago_mensual\": promedio[\"promedio_pago\"],\n",
    "    \"pais\": \"Desconocido\"\n",
    "})\n",
    "\n",
    "\n",
    "# Segunda verificación de valores nulos\n",
    "print('\\nSegunda verificación de nulos:')\n",
    "for columna in df.columns:\n",
    "    print(\n",
    "        f\"Nulos en {columna}: \",\n",
    "        df.filter(col(columna).isNull()).count()\n",
    "    )\n",
    "\n",
    "\n",
    "# Feature engineering y filtrado\n",
    "df = df.withColumn(\n",
    "    \"ingreso_anual\",\n",
    "    col(\"pago_mensual\") * 12\n",
    ")\n",
    "\n",
    "df_an = df.filter(\n",
    "    (col(\"edad\") >= 21) &\n",
    "    (col(\"pago_mensual\") > 0) &\n",
    "    (col(\"estado_suscripcion\") == \"Activa\")\n",
    ")\n",
    "\n",
    "\n",
    "# Agregaciones y análisis final\n",
    "df_an = (\n",
    "    df_an\n",
    "    .groupBy(\"pais\", \"tipo_suscripcion\")\n",
    "    .agg(\n",
    "        avg(col(\"ingreso_anual\")).alias(\"ingreso_promedio_anual\"),\n",
    "        count(col(\"cliente_id\")).alias(\"total_clientes\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df_an = df_an.filter(\n",
    "    (col(\"ingreso_promedio_anual\") > 500) &\n",
    "    (col(\"total_clientes\") >= 10)\n",
    ")\n",
    "\n",
    "df_an = df_an.orderBy(\n",
    "    col(\"ingreso_promedio_anual\").desc()\n",
    ")\n",
    "\n",
    "df_an.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04f08cbc-ccbf-4fc3-9dcc-e25950a7e32b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "etl_digital_platform",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
