{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73d0fc37-d267-49a3-8ae4-498bc104b025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Descripción general del proyecto**\n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un **pipeline ETL completo** para el análisis del consumo de energía eléctrica en una cadena de tiendas físicas en distintos países de Latinoamérica, utilizando datos operativos reales simulados a nivel diario.\n",
    "\n",
    "A lo largo del proyecto se trabaja con un dataset de alta granularidad que contiene información sobre consumo energético, demanda eléctrica, características físicas de las tiendas y su estado operativo. El enfoque principal es **limpiar, transformar y enriquecer los datos**, garantizando su calidad antes de realizar cualquier análisis agregado.\n",
    "\n",
    "El proyecto se implementa utilizando Pandas, PySpark y SQL, permitiendo comparar enfoques y reforzar el entendimiento de los principios fundamentales de ETL, tales como:\n",
    "\n",
    "* orden correcto del flujo de transformación,\n",
    "* manejo de valores nulos con criterio de negocio,\n",
    "* creación de métricas derivadas relevantes,\n",
    "* uso adecuado de filtros antes y después de agregaciones.\n",
    "\n",
    "Este trabajo está diseñado tanto como ejercicio de aprendizaje profundo como **proyecto demostrable de portafolio** orientado a análisis de datos y data engineering.\n",
    "\n",
    "## Contexto del proyecto\n",
    "\n",
    "En este notebook se desarrolla un proceso de **ETL y transformación de datos utilizando Pandas**, aplicado a un conjunto de datos de consumo energético diario de tiendas físicas.\n",
    "\n",
    "El objetivo es preparar un dataset limpio y coherente a partir de datos crudos, abordando problemas comunes en entornos reales como:\n",
    "\n",
    "* registros de tiendas cerradas,\n",
    "* valores nulos en variables operativas críticas,\n",
    "* necesidad de imputación basada en características del negocio.\n",
    "\n",
    "Durante el proceso se crean columnas derivadas que permiten evaluar indicadores clave de eficiencia energética, como el consumo y la demanda eléctrica normalizados por área de la tienda.\n",
    "El enfoque prioriza **claridad, orden lógico y reproducibilidad**, siguiendo buenas prácticas de análisis de datos en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f1d0a12-f01d-4175-95f5-4061ee450041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# CARGA DEL DATASET\n",
    "df = pd.read_csv(\n",
    "    '/Volumes/workspace/default/raw_data/consumo_energia_tiendas_diario_2023_2024.csv'\n",
    ")\n",
    "\n",
    "\n",
    "# ESQUEMA DEL SET DE DATOS\n",
    "print(\"Esquema:\")\n",
    "print(df.head(10))\n",
    "\n",
    "\n",
    "# INFORMACIÓN DEL DATASET\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nColumnas del set de datos:\")\n",
    "print(list(df.columns))\n",
    "\n",
    "print(\"\\nNulos en columnas\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "\n",
    "'''\n",
    "Aunque las tiendas presentan consumo eléctrico en días cerrados debido a cargas base y sistemas auxiliares, estos registros no representan operación comercial normal. Para evitar distorsionar métricas de eficiencia energética, se excluyen de los análisis operativos.\n",
    "\n",
    "Existen 5482 registros nulos en las columnas de area_m2, consumo_kwh y demanda_kw. Ya que es muy importante conservar la información completa \n",
    "de estas columnas, imputaremos los valores utilizando el promedio de los datos, considerando el tipo de tienda y el país donde se encuentran \n",
    "localizadas. \n",
    "'''\n",
    "\n",
    "\n",
    "# FILTRADO DE TIENDAS ACTIVAS\n",
    "df_active = df[df['estado_tienda'] == 'Activa']\n",
    "\n",
    "\n",
    "# DETERMINAMOS PROMEDIO DE DATOS\n",
    "# Área\n",
    "promedio = (\n",
    "    df_active\n",
    "        .groupby(['pais', 'tipo_tienda'])\n",
    "        .agg(\n",
    "            promedio_area_m2=('area_m2', 'mean'),\n",
    "            promedio_consumo_kwh=('consumo_kwh', 'mean'),\n",
    "            promedio_demanda_kw=('demanda_kw', 'mean')\n",
    "        )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "print(promedio)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# UNIMOS PROMEDIOS AL DATASET ACTIVO\n",
    "df_active = df_active.merge(\n",
    "    promedio,\n",
    "    on=['pais', 'tipo_tienda'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "# IMPUTACIÓN DE NULOS\n",
    "df_active['area_m2'] = df_active['area_m2'].fillna(df_active['promedio_area_m2'])\n",
    "df_active['consumo_kwh'] = df_active['consumo_kwh'].fillna(df_active['promedio_consumo_kwh'])\n",
    "df_active['demanda_kw'] = df_active['demanda_kw'].fillna(df_active['promedio_demanda_kw'])\n",
    "\n",
    "\n",
    "# ELIMINAMOS COLUMNAS AUXILIARES\n",
    "df_active = df_active.drop(\n",
    "    ['promedio_area_m2', 'promedio_consumo_kwh', 'promedio_demanda_kw'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df_active.isna().sum())\n",
    "\n",
    "\n",
    "# CREACIÓN DE KPIs\n",
    "df_active['kpi_kwh/m2'] = df_active['consumo_kwh'] / df_active['area_m2']\n",
    "df_active['kpi_kw/m2'] = df_active['demanda_kw'] / df_active['area_m2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "720df635-37ac-4fe9-8e11-2aae5e9e0b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab1d77e2-96ca-4a5c-abd8-4328138a277c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_active.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fda52c8-074c-47a1-91ff-0fe386f6cfc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "etl_energia_electrica",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
